@book{kalapalaFacialExpressionRecognition2020,
  title = {Facial {{Expression Recognition}} from {{3D Facial Landmarks Reconstructed}} from {{Images}}},
  author = {Kalapala, Limysh and Yadav, Harshit and Kharwar, Himanshu and Susan, Seba},
  date = {2020-12-16},
  pages = {5},
  doi = {10.1109/iSSSC50941.2020.9358815},
  abstract = {Direct classification of normalized and flattened 3D facial landmarks reconstructed from 2D images is proposed in this paper for recognizing eight types of facial expressions depicting the emotions of- sadness, anger, contempt, disgust, fear, happiness, neutral and surprised. The first stage is the 3D projection of 2D facial landmarks. The pre-trained convolutional Face Alignment Network (FAN) proposed recently for 2D/3D face alignment is used for the purpose. The 3D cartesian coordinates are translated to the spherical coordinate system prior to the classification stage. A variety of classifiers are tried and tested for classifying the 68 facial landmarks, for both the coordinate systems. The benchmark CK+ video dataset is used for the experimentation; the last frame of each video that depicts the peak of each emotion is used as the input image. The experimental results indicate that direct classification of normalized and flattened 3D facial landmarks in the spherical coordinate system yields the highest accuracy for the support vector machine classifier with grid search for determining optimal parameters.},
  pagetotal = {1}
}

@article{koBriefReviewFacial2018,
  title = {A {{Brief Review}} of {{Facial Emotion Recognition Based}} on {{Visual Information}}},
  author = {Ko, Byoung},
  date = {2018-01-30},
  journaltitle = {Sensors},
  volume = {18},
  number = {2},
  pages = {401},
  issn = {1424-8220},
  doi = {10.3390/s18020401},
  url = {https://www.mdpi.com/1424-8220/18/2/401},
  urldate = {2024-09-04},
  abstract = {Facial emotion recognition (FER) is an important topic in the fields of computer vision and artificial intelligence owing to its significant academic and commercial potential. Although FER can be conducted using multiple sensors, this review focuses on studies that exclusively use facial images, because visual expressions are one of the main information channels in interpersonal communication. This paper provides a brief review of researches in the field of FER conducted over the past decades. First, conventional FER approaches are described along with a summary of the representative categories of FER systems and their main algorithms. Deep-learning-based FER approaches using deep networks enabling “end-to-end” learning are then presented. This review also focuses on an up-to-date hybrid deep-learning approach combining a convolutional neural network (CNN) for the spatial features of an individual frame and long short-term memory (LSTM) for temporal features of consecutive frames. In the later part of this paper, a brief review of publicly available evaluation metrics is given, and a comparison with benchmark results, which are a standard for a quantitative comparison of FER researches, is described. This review can serve as a brief guidebook to newcomers in the field of FER, providing basic knowledge and a general understanding of the latest state-of-the-art studies, as well as to experienced researchers looking for productive directions for future work.},
  langid = {english},
  file = {files/12/Ko - 2018 - A Brief Review of Facial Emotion Recognition Based on Visual Information.pdf}
}

@article{sariyanidiAutomaticAnalysisFacial2015,
  title = {Automatic {{Analysis}} of {{Facial Affect}}: {{A Survey}} of {{Registration}}, {{Representation}}, and {{Recognition}}},
  shorttitle = {Automatic {{Analysis}} of {{Facial Affect}}},
  author = {Sariyanidi, Evangelos and Gunes, Hatice and Cavallaro, Andrea},
  date = {2015-06-01},
  journaltitle = {IEEE Trans. Pattern Anal. Mach. Intell.},
  volume = {37},
  number = {6},
  pages = {1113--1133},
  issn = {0162-8828, 2160-9292},
  doi = {10.1109/TPAMI.2014.2366127},
  url = {http://ieeexplore.ieee.org/document/6940284/},
  urldate = {2024-09-04},
  abstract = {Automatic affect analysis has attracted great interest in various contexts including the recognition of action units and basic or non-basic emotions. In spite of major efforts, there are several open questions on what the important cues to interpret facial expressions are and how to encode them. In this paper, we review the progress across a range of affect recognition applications to shed light on these fundamental questions. We analyse the state-of-the-art solutions by decomposing their pipelines into fundamental components, namely face registration, representation, dimensionality reduction and recognition. We discuss the role of these components and highlight the models and new trends that are followed in their design. Moreover, we provide a comprehensive analysis of facial representations by uncovering their advantages and limitations; we elaborate on the type of information they encode and discuss how they deal with the key challenges of illumination variations, registration errors, head-pose variations, occlusions, and identity bias. This survey allows us to identify open issues and to define future directions for designing real-world affect recognition systems.},
  langid = {english},
  file = {files/10/Sariyanidi et al. - 2015 - Automatic Analysis of Facial Affect A Survey of Registration, Representation, and Recognition.pdf}
}
