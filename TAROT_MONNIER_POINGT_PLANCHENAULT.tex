\documentclass{rapport}
\usepackage{lipsum}
\usepackage{graphicx}
\title{TAROT_MONNIER_POINGT_PLANCHENAULT} %Titre du fichier

\begin{document}

%----------- Informations du rapport ---------

\logo{IMAGES/Logo Esiea - noir.png}
\titre{Rapport MLChallenge} %Titre du fichier .pdf
\cours{Machine Learning Challenge} %Nom du cours

\enseignant{Thibault \textsc{GEOFFROY}} %Nom de l'enseignant

\eleves{Bastien \textsc{TAROT} \\
    Raphael \textsc{MONNIER} \\
    Tanguy \textsc{POINGT} \\
    Allan \textsc{PLANCHENAULT} } %Nom des élèves

%----------- Initialisation -------------------

\fairemarges %Afficher les marges
\fairepagedegarde %Créer la page de garde
\tabledematieres %Créer la table de matières

%------------ Corps du rapport ----------------

\section{Introduction}

La reconnaissance des émotions est un domaine en pleine expansion qui suscite l'intérêt de
nombreux chercheurs en raison des défis complexes qu'il pose.
Malgré les avancées réalisées, ce problème reste encore partiellement résolu.
Ce champ d'étude est vaste, mais pour ce projet, nous nous concentrerons sur les émotions dites de base selon le modèle d'Ekman :
la joie, la colère, le dégoût, la tristesse, la peur et la surprise, en ajoutant également l'absence d'émotion,
c'est-à-dire l'état « neutre ».\\

\subsection{Objectifs du Projet}
Pour développer un système de reconnaissance des émotions en utilisant une approche de machine learning,
il est généralement recommandé de suivre un pipeline structuré.\\

Dans le cadre de ce projet, apres la mise en place des différents sujets d'introduction nous aborderons les grands thèmes suivants :\\

1.Prétraitement et Extraction des Features :
Les étapes nécessaires pour préparer les données et extraire les caractéristiques pertinentes pour la reconnaissance des émotions.\\

2.Modèles Choisis :
Les différents modèles de machine learning sélectionnés pour cette tâche et les raisons de leur choix.\\

3.Évaluation des Modèles :
Les méthodes et les métriques utilisées pour évaluer la performance des modèles de reconnaissance d émotions.\\

4.Discussion des Résultats :
Une analyse critique des résultats obtenus,
mettant en évidence les points forts et les limitations des approches adoptées.\\

Cette structure permettra de couvrir de manière exhaustive les aspects clés du développement
d'un système de reconnaissance des émotions basé sur l'apprentissage automatique.

\subsection{Etat de l'art}

\section{Analyse des Données}
\subsection{Description des Données}

Le visage manifeste près de 2/3 des émotions chez un humain. \cite{koBriefReviewFacial2018}
Les zones les plus démonstratives sont
principalement situé au niveau des lèvres, des sourcils, des yeux mais
également des yeux et du nez (malgré qu'ils sont moins significatif sur leurs
représentations). \cite{koBriefReviewFacial2018} Les données sont représentées dans
un CSV. Il y a au total 978 observations, toutes sous le même format. Chacune
d'entre est représenté sur une même ligne et 138 colonnes. La première colonne
est réservé pour l'ID de l'image. La deuxième colonne représente simplement le
label de l'observation. Pour les 136 colonnes restantes, elles sont séparées
en deux sous-parties. En effet, les 64 premières valeurs et les 64 dernières
valeurs sont respectivement les coordonnées en X et en Y de chaque points
encadrant le visage et plus précisément les zones mentionnées plus tôt.

\subsection{Exploration des Données}

Nous allons dans un premier temps nous familiariser avec les données afin de comprendre leur structure
mais également leur distribution. Nous remarquons que notre jeu de données est de manière générale bien
réparti comme présenté sur la figure \ref*{fig: emotion_distribution}. Nous notons tout de même une quantité
moins importante de données pour les labels 'happy' et 'neutral'.
\insererfigure{IMAGES/distribution_emotion_jeu_donnee.png}{10cm}{Disribution des émotions dans le jeu de données}{emotion_distribution}

Comme précisé dans la partie précédente, nous disposons d'un fichier CSV contenant les coordonnées des points clés du visage. Pour nous familiariser
avec les données, nous allons visualiser quelques visages marqués de ces points clés comme présenté sur les figures
\ref*{fig: face_1_landmarks} et \ref*{fig: face_2_landmarks} :
\insererfigure{IMAGES/exemple1_landmark_jeu_donnee.png}{7cm}{Visage surpris avec ses points clés}{face_1_landmarks}
\insererfigure{IMAGES/exemple2_landmark_jeu_donnee.png}{7cm}{Visage triste avec ses points clés}{face_2_landmarks}


\section{Prétraitement et Extraction des Features}
\subsection{Prétraitement des Données}
Comme spécifié auparavant, nous disposons donc des 138 caractéristiques représentant les coordonnées des points repères du visage.
Avant de pouvoir construire notre modèle, il est essentiel de normaliser ces données.
Nous les normalisons donc selon la manière suivante \cite{kalapalaFacialExpressionRecognition2020} :\\

\begin{equation}
    X = \frac{(X - Xmean)} {Xstd}
\end{equation}\\

En parallèle, nous devons également appliquer un traitement sur les labels des données.
En effet ceux-ci correspondent à une variable qualitative parmi les 7 émotions.
Nous devons donc l'encoder en entier entre 0 et 6, chaque entier correspondant à une émotion en particulier.
Une fois ces traitements appliqués, nous pouvons commencer à réfléchir au modèle à utiliser.\\

Nous avons également tenter de travailler avec les images.
En effet, les repères de visage présentent tout de même plusieurs inconvénients et une partie de l'information est perdue.
Les images quant à elle permettent d'avoir les textures,
les rides du visage et autres informations susceptibles d'aider dans la reconnaissance d'émotions.
Néanmoins, de nouveau défis surviennent lorsque nous utilisons les images, comme la luminosité ou encore l'orientation du visage.
Nous supposons également que la construction du modèle ainsi que sa compléxité seront décuplées.

\subsection{Extraction des Features}
\subsection{Modèles et Méthodologies}

\section{Modèle(s) choisi(s)}
\subsection{Paramétrage et Entraînement}

L'utilisation d'un modèle Support Vector Machine (SVM) n'est pas nouvelle est a déjà prouvé ses performances dans la reconnaissance
d'émotions \cite{kalapalaFacialExpressionRecognition2020}. Nous avons donc décidé d'utiliser ce modèle couplé à une GridSearch
afin de trouver les hyperparamètres optimaux pour le modèle.\\

GridSearch est une méthode utilisée afin de trouver les hyperparamètres optimaux pour un modèle. Elle prend en paramètre une grille
d'hyperparamètres et va tester ensuite chaque combinaison pour faire ressortir la meilleure d'entre elle. Pour vérifier la performance
des paramètres, GridSearch utilise la méthode "k-fold cross-validation" qui consiste à diviser les données d'entraînement en plusieurs
sous-ensemble. Le modèle est entraîné ensuite sur l'un de ces sous-ensemble et est évalué sur le reste des données. Ce processus est répété
k fois et permet d'éviter le surapprentissage du modèle. La meilleure combinaison d'hyperparamètres est ensuite utilisée pour entraîner le modèle
sur l'ensemble des données d'entraînement. Il est important de noter que même si cette méthode permet de trouver les hyperparamètres optimaux, elle
reste tout de même très gourmande en temps et en ressources.\\

Nous avons donc décidé d'utiliser cette méthode afin d'obtenir les meilleurs hyperparamètres pour le modèle SVM. Il possède plusieurs paramètres :\\
\\- C aussi appelé paramètre de régularisation qui permet de gérer la marge. Une grande valeur de C implique une petite marge mais peu d'erreurs de classification
tandis qu'une petite valeur de C entraîne davantage d'erreur de classification mais une marge plus grande qui implique une plus grande généralisation.\\
- Le kernel qui permet de séparer les données. Nous pouvons choisir ici parmi plusieurs kernel dont 'rbf', 'linear' ou encore
'poly' ou 'sigmoid'.\\
- Gamma qui est paramètre uniquement présent pour les kernels non-linéaires et qui permet d'épouser davantage la "forme" des données
\subsection{Expérimentations}
\subsection{Résultats}

Le meilleur modèle SVM entraîné sur les données fournies présente une précision de 80.74\% sur les données de tests. La matrice de confusion est présentée ci-après :


\section{Évaluation des Modèles}
\subsection{Analyse des Résultats}

\subsection{Discussions et Limites}

Le modèle SVM s'est montré plutôt performant avec les paramètres que nous avons choisis. Néanmoins, la précision du modèle est sujette à une certaine limite causée
majoritairement par le type et la forme des données en entrée du modèle. En effet, les points clés du visage ne sont pas forcément toujours caractéristique d'une émotion
et les points peuvent beaucoup varier d'une personne à l'autre quand bien même l'émotion représentée est la même. Les points repères du visage sont donc parfois biaisés selon
l'origine de la personne ou la forme de son visage. Nous pouvons cependant retenir que ce modèle présente un temps computationel plutôt court, notamment grâce au nombre réduit
de caractéristiques en entrée.

\section{Conclusion}

\bibliographystyle{ieeetr}
\bibliography{MLChallenge.bib}

\end{document}